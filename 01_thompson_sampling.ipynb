{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7038827c-251b-4daf-b9d7-080b2ca7af72",
   "metadata": {},
   "source": [
    "# Thompson sampling\n",
    "\n",
    "From Wikipedia [^1]\n",
    "> Thompson sampling,[1][2][3] named after William R. Thompson, is a heuristic for choosing actions that addresses the exploration-exploitation dilemma in the multi-armed bandit problem. It consists of choosing the action that maximizes the expected reward with respect to a randomly drawn belief.\n",
    "\n",
    "[^1]: https://en.wikipedia.org/wiki/Thompson_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8654c5e-cf8f-4791-84c3-75f052ef76a4",
   "metadata": {},
   "source": [
    "# Resources\n",
    "- https://gdmarmerola.github.io/ts-for-bernoulli-bandit/\n",
    "- https://github.com/gdmarmerola/interactive-intro-rl/blob/master/notebooks/ts_for_multi_armed_bandit.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "570d2378-a672-415a-8ac3-85ec1311804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MAB:\n",
    "    def __init__(self, bandit_probs):\n",
    "        self.bandit_probs = bandit_probs\n",
    "\n",
    "    def draw(self, k):\n",
    "        reward = np.random.binomial(1, self.bandit_probs[k]) # Returns either 0 or 1\n",
    "        regret = np.max(self.bandit_probs) - self.bandit_probs[k]\n",
    "        return reward, regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6798125d-a4c2-424e-bb69-a2f7c32a5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class eGreedyPolicy:\n",
    "    def __init__(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def choose_bandit(self, k_array, reward_array, n_bandits):\n",
    "        total_success = reward_array.sum(axis=1)\n",
    "        total_count = k_array.sum(axis=1)\n",
    "        success_ratio = total_success/total_count\n",
    "        \n",
    "        best_action = np.argmax(success_ratio)\n",
    "        if np.random.random() < self.epsilon:\n",
    "            # Returning random action, excluding best\n",
    "            return np.random.choice(list(range(n_bandits)) - best_action)\n",
    "        else:\n",
    "            # Returning best greedy action.\n",
    "            return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "278a8cac-b6b0-4e4d-9897-bc6b31d43545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e-greedy policy\n",
    "class UCBPolicy:\n",
    "    \n",
    "    # initializing\n",
    "    def __init__(self):\n",
    "        \n",
    "        # nothing to do here\n",
    "        pass\n",
    "    \n",
    "    # choice of bandit\n",
    "    def choose_bandit(self, k_array, reward_array, n_bandits):\n",
    "        \n",
    "        # sucesses and total draws\n",
    "        success_count = reward_array.sum(axis=1)\n",
    "        total_count = k_array.sum(axis=1)\n",
    "        \n",
    "        # ratio of sucesses vs total\n",
    "        success_ratio = success_count/total_count\n",
    "        \n",
    "        # computing square root term\n",
    "        sqrt_term = np.sqrt(2*np.log(np.sum(total_count))/total_count)\n",
    "        \n",
    "        # returning best greedy action\n",
    "        return np.argmax(success_ratio + sqrt_term)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66611c9a-871e-4ba9-8228-ff6276e7d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSPolicy:\n",
    "    \n",
    "    # initializing\n",
    "    def __init__(self):\n",
    "        \n",
    "        # nothing to do here\n",
    "        pass\n",
    "    \n",
    "    # choice of bandit\n",
    "    def choose_bandit(self, k_array, reward_array, n_bandits):\n",
    "        # list of samples, for each bandit\n",
    "        samples_list = []\n",
    "        \n",
    "        # sucesses and failures\n",
    "        success_count = reward_array.sum(axis=1)\n",
    "        failure_count = k_array.sum(axis=1) - success_count\n",
    "                    \n",
    "        # drawing a sample from each bandit distribution\n",
    "        samples_list = [np.random.beta(1 + success_count[bandit_id], 1 + failure_count[bandit_id]) for bandit_id in range(n_bandits)]\n",
    "                                \n",
    "        # returning bandit with best sample\n",
    "        return np.argmax(samples_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31bab437-cb2c-4a2b-8536-bbc37b6245be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# defining a set of bandits with known probabilites\n",
    "bandit_probs = [0.35, 0.40, 0.30, 0.25]\n",
    "\n",
    "# instance of our MAB class\n",
    "mab = MAB(bandit_probs)\n",
    "\n",
    "# policy\n",
    "egreedy_policy = eGreedyPolicy(0.1)\n",
    "ucb_policy = UCBPolicy()\n",
    "ts_policy = TSPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6159409-b678-4778-92b3-f13ad52ac17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy(k_array, reward_array, N_BANDITS):\n",
    "    return np.random.choice(range(N_BANDITS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c13cce8b-a9fd-4a35-bbad-ef4fc04f1b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1297. 1264. 1199. 1240.] [472. 511. 352. 305.] 370.7500000000091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/ipykernel_14289/1459101977.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "  success_ratio = total_success/total_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1558. 3016.  223.  203.] [ 529. 1241.   58.   49.] 130.64999999999668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/ipykernel_14289/2987556313.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  success_ratio = success_count/total_count\n",
      "/var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/ipykernel_14289/2987556313.py:21: RuntimeWarning: divide by zero encountered in log\n",
      "  sqrt_term = np.sqrt(2*np.log(np.sum(total_count))/total_count)\n",
      "/var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/ipykernel_14289/2987556313.py:21: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sqrt_term = np.sqrt(2*np.log(np.sum(total_count))/total_count)\n",
      "/var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/ipykernel_14289/2987556313.py:21: RuntimeWarning: invalid value encountered in divide\n",
      "  sqrt_term = np.sqrt(2*np.log(np.sum(total_count))/total_count)\n",
      "/var/folders/7m/74_ct3hx33d878n626w1wxyc0000gn/T/ipykernel_14289/2987556313.py:21: RuntimeWarning: divide by zero encountered in divide\n",
      "  sqrt_term = np.sqrt(2*np.log(np.sum(total_count))/total_count)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 968. 3061.  566.  405.] [ 329. 1219.  169.  108.] 165.75000000000097\n",
      "[ 522. 4192.  249.   37.] [ 181. 1668.   83.    6.] 56.549999999999635\n"
     ]
    }
   ],
   "source": [
    "N_DRAWS = 5000\n",
    "N_BANDITS = len(mab.bandit_probs)\n",
    "\n",
    "policies = [random_policy, egreedy_policy.choose_bandit, ucb_policy.choose_bandit, ts_policy.choose_bandit]\n",
    "\n",
    "for policy in policies:\n",
    "    k_array = np.zeros((N_BANDITS, N_DRAWS))\n",
    "    reward_array = np.zeros((N_BANDITS, N_DRAWS))\n",
    "    total_regret = 0\n",
    "    \n",
    "    for i in range(N_DRAWS):\n",
    "        k = policy(k_array, reward_array, N_BANDITS)\n",
    "        reward, regret = mab.draw(k)\n",
    "        k_array[k, i] = 1\n",
    "        reward_array[k, i] = reward\n",
    "        total_regret += regret\n",
    "    print(k_array.sum(axis=1), reward_array.sum(axis=1), total_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42ad28-aeb8-4bcf-b28d-13bb79149b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
